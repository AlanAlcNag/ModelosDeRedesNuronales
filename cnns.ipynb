{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, MaxPool2D, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "satelites_data = np.loadtxt('satelites_grises.csv', delimiter=',') # 128x128\n",
    "satelites_X = satelites_data[:,1:].reshape(-1,128,128,1)\n",
    "satelites_y = satelites_data[:,0]\n",
    "#satelites_X_train, satelites_X_test, satelites_y_train, satelites_y_test = train_test_split(satelites_X, satelites_y, stratify=satelites_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_data = np.loadtxt('emojis.txt') # 32x32\n",
    "emojis_X = emojis_data[:,1:].reshape(-1,32,32,1)\n",
    "emojis_y = emojis_data[:,0] - 1\n",
    "#emoji_X_train, emoji_X_test, emoji_y_train, emoji_y_test = train_test_split(emojis_X, emojis_y, stratify=emojis_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data = pd.read_csv(\"fashion-mnist_train.csv\") # 28x28\n",
    "mnist_test_data = pd.read_csv('fashion-mnist_test.csv')\n",
    "\n",
    "mnist_X_train = mnist_train_data.iloc[:,1:].to_numpy().reshape(-1,28,28,1) / 255\n",
    "mnist_y_train = mnist_train_data.iloc[:,0]\n",
    "mnist_X_test = mnist_test_data.iloc[:,1:].to_numpy().reshape(-1,28,28,1) / 255\n",
    "mnist_y_test = mnist_test_data.iloc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = StratifiedKFold(shuffle=True, random_state=8)\n",
    "def scoring_fun(y_true, y_pred):\n",
    "    reports.append(classification_report(y_true, y_pred, output_dict=True))\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_summary(scoring_reports):\n",
    "    acc = np.array([])\n",
    "    macro_prec = np.array([])\n",
    "    macro_rec = np.array([])\n",
    "    macro_f1 = np.array([])\n",
    "    macro_supp = np.array([])\n",
    "    weigh_prec = np.array([])\n",
    "    weigh_rec = np.array([])\n",
    "    weigh_f1 = np.array([])\n",
    "    weigh_supp = np.array([])\n",
    "\n",
    "    for report in scoring_reports:\n",
    "        acc = np.append(acc, report['accuracy'])\n",
    "        macro_prec = np.append(macro_prec, report['macro avg']['precision'])\n",
    "        macro_rec = np.append(macro_rec, report['macro avg']['recall'] )\n",
    "        macro_f1 = np.append(macro_f1, report['macro avg']['f1-score'])\n",
    "        macro_supp = np.append(macro_supp, report['macro avg']['support'])\n",
    "        weigh_prec = np.append(weigh_prec, report['weighted avg']['precision'])\n",
    "        weigh_rec = np.append(weigh_rec, report['weighted avg']['recall'] )\n",
    "        weigh_f1 = np.append(weigh_f1, report['weighted avg']['f1-score'])\n",
    "        weigh_supp = np.append(weigh_supp, report['weighted avg']['support'])\n",
    "    \n",
    "    print('\\t\\t\\tMean\\t\\t\\tStDev')\n",
    "    print(f'\\tACCURACY:\\t{acc.mean()}\\t{acc.std()}\\n')\n",
    "    print(f'Macro\\tPrecision:\\t{macro_prec.mean()}\\t{macro_prec.std()}')\n",
    "    print(f'\\tRecall:\\t\\t{macro_rec.mean()}\\t{macro_rec.std()}')\n",
    "    print(f'\\tf1:\\t\\t{macro_f1.mean()}\\t{macro_f1.std()}')\n",
    "    print(f'\\tsupport:\\t\\t{macro_supp.mean()}\\n')\n",
    "    print(f'Weight\\tPrecision:\\t{weigh_prec.mean()}\\t{weigh_prec.std()}')\n",
    "    print(f'\\tRecall:\\t\\t{weigh_rec.mean()}\\t{weigh_rec.std()}')\n",
    "    print(f'\\tf1:\\t\\t{weigh_f1.mean()}\\t{weigh_f1.std()}')\n",
    "    print(f'\\tsupport:\\t\\t{weigh_supp.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alan\\AppData\\Local\\Temp/ipykernel_23208/2301743090.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  emojis_clf = KerasClassifier(build_fn=emojis_cnn, epochs= 1, batch_size=32, verbose=1) # ajustar epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 6ms/step - loss: 0.9059 - accuracy: 0.6609\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 1s 6ms/step - loss: 0.9064 - accuracy: 0.6635\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 1s 6ms/step - loss: 0.8733 - accuracy: 0.6842\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 1s 6ms/step - loss: 0.8574 - accuracy: 0.6959\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 1s 6ms/step - loss: 0.8753 - accuracy: 0.6781\n",
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "def emojis_cnn():\n",
    "    emojis_model = Sequential()\n",
    "    emojis_model.add(Conv2D(32, (2,2), activation='relu', input_shape=(32,32,1)))\n",
    "    emojis_model.add(MaxPool2D(3,3))\n",
    "    emojis_model.add(Flatten())\n",
    "    emojis_model.add(Dense(32, activation='relu'))\n",
    "    emojis_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    emojis_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return emojis_model\n",
    "\n",
    "emojis_clf = KerasClassifier(build_fn=emojis_cnn, epochs= 1, batch_size=32, verbose=1) # ajustar epochs\n",
    "\n",
    "reports = []\n",
    "\n",
    "acuracy = cross_validate(emojis_clf, X=emojis_X, y=emojis_y, cv=fold ,scoring=make_scorer(scoring_fun))\n",
    "kfold_summary(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70       101\n",
      "         1.0       0.98      0.59      0.74       101\n",
      "         2.0       0.99      0.98      0.99       101\n",
      "         3.0       0.75      0.62      0.67        91\n",
      "         4.0       0.75      0.86      0.80       100\n",
      "\n",
      "    accuracy                           0.78       494\n",
      "   macro avg       0.81      0.78      0.78       494\n",
      "weighted avg       0.81      0.78      0.78       494\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.74      0.69       100\n",
      "         1.0       0.91      0.78      0.84       102\n",
      "         2.0       0.99      1.00      1.00       101\n",
      "         3.0       0.78      0.52      0.62        91\n",
      "         4.0       0.70      0.92      0.80       100\n",
      "\n",
      "    accuracy                           0.80       494\n",
      "   macro avg       0.81      0.79      0.79       494\n",
      "weighted avg       0.81      0.80      0.79       494\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.43      0.55       100\n",
      "         1.0       0.73      0.88      0.80       102\n",
      "         2.0       1.00      1.00      1.00       101\n",
      "         3.0       0.44      0.85      0.58        91\n",
      "         4.0       0.85      0.33      0.47       100\n",
      "\n",
      "    accuracy                           0.70       494\n",
      "   macro avg       0.76      0.70      0.68       494\n",
      "weighted avg       0.76      0.70      0.68       494\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.82      0.73       100\n",
      "         1.0       0.81      0.80      0.81       102\n",
      "         2.0       1.00      1.00      1.00       101\n",
      "         3.0       0.82      0.67      0.74        90\n",
      "         4.0       0.80      0.74      0.77       101\n",
      "\n",
      "    accuracy                           0.81       494\n",
      "   macro avg       0.82      0.81      0.81       494\n",
      "weighted avg       0.82      0.81      0.81       494\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.70      0.72       100\n",
      "         1.0       0.96      0.74      0.83       102\n",
      "         2.0       0.98      1.00      0.99       101\n",
      "         3.0       0.81      0.61      0.70        90\n",
      "         4.0       0.62      0.93      0.75       101\n",
      "\n",
      "    accuracy                           0.80       494\n",
      "   macro avg       0.82      0.80      0.80       494\n",
      "weighted avg       0.82      0.80      0.80       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mnist_cnn():\n",
    "    mnist_model = Sequential()\n",
    "    mnist_model.add(Conv2D(32, (2,2), activation='relu', input_shape=(28,28,1)))\n",
    "    mnist_model.add(MaxPool2D(3,3))\n",
    "    mnist_model.add(Flatten())\n",
    "    mnist_model.add(Dense(32, activation='relu'))\n",
    "    mnist_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    mnist_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return mnist_model\n",
    "\n",
    "mnist_clf = KerasClassifier(build_fn=mnist_cnn, epochs= 1, batch_size=32, verbose=1) # ajustar epochs\n",
    "\n",
    "mnist_clf.fit(mnist_X_train, mnist_y_train)\n",
    "\n",
    "mnist_pred = mnist_clf.predict(mnist_X_test)\n",
    "print(classification_report(mnist_y_test, mnist_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def satelite_cnn():\n",
    "    satelite_model = Sequential()\n",
    "    satelite_model.add(Conv2D(32, (2,2), activation='relu', input_shape=(128,128,1)))\n",
    "    satelite_model.add(MaxPool2D(3,3))\n",
    "    satelite_model.add(Conv2D(64, (2,2), activation='relu'))\n",
    "    satelite_model.add(MaxPool2D(3,3))\n",
    "    satelite_model.add(Flatten())\n",
    "    satelite_model.add(Dense(64, activation='relu'))\n",
    "    satelite_model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    satelite_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return satelite_model\n",
    "\n",
    "satelite_clf = KerasClassifier(build_fn=satelite_cnn, epochs= 1, batch_size=32, verbose=1) # ajustar epochs\n",
    "\n",
    "reports = []\n",
    "\n",
    "acuracy = cross_validate(satelite_clf, X=satelites_X, y=satelites_y, cv=fold ,scoring=make_scorer(scoring_fun))\n",
    "kfold_summary(reports)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
